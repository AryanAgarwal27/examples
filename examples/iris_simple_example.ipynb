{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division, unicode_literals, with_statement\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression as logreg\n",
    "import numpy as np\n",
    "from confidentlearning.classification import RankPruning\n",
    "from confidentlearning.noise_generation import generate_noisy_labels\n",
    "from confidentlearning.util import value_counts\n",
    "from confidentlearning.latent_algebra import compute_inv_noise_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **rankpruning** is the first practical *(works for any classifier, runs fast, robust to poor probability estimation)* algorithm for multiclass learning with noisy labels. Its comprised of components from the theory and algorithsm of **confident learning**. It's a Python class that wraps around any classifier as long as .fit(X, y, sample_weight), .predict(X), .predict_proba(X) are defined. Inspect the **confidentlearning** package for documentation.\n",
    "\n",
    "## Here we show the performance of multiclass rankpruning wrapped around a sklearn LogisiticRegression classifier versus LogisticRegression without any help from confident learning on the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT confident learning, Iris dataset test accuracy: 0.27\n",
      "\n",
      "Now we show the improvement using confident learning to characterize the noise\n",
      "and learn on the data that is (with high confidence) labeled correctly.\n",
      "\n",
      "WITH confident learning (noise matrix given), Iris dataset test accuracy: 0.97\n",
      "WITH confident learning (noise matrix and inverse noise matrix given), Iris dataset test accuracy: 0.97\n",
      "WITH confident learning (using latent noise matrix estimation), Iris dataset test accuracy: 0.93\n",
      "WITH confident learning (using calibrated confident joint), Iris dataset test accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Seed for reproducibility\n",
    "seed = 2\n",
    "rp = RankPruning(clf = logreg(), seed = seed)\n",
    "np.random.seed(seed = seed)\n",
    "\n",
    "# Get iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we only take the first two features.\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Generate lots of noise.\n",
    "noise_matrix = np.array([\n",
    "    [0.5, 0.0, 0.0],\n",
    "    [0.5, 1.0, 0.5],\n",
    "    [0.0, 0.0, 0.5],\n",
    "])\n",
    "\n",
    "py = value_counts(y_train)\n",
    "s = generate_noisy_labels(y_train, noise_matrix)\n",
    "\n",
    "print('WITHOUT confident learning,', end=\" \")\n",
    "clf = logreg()\n",
    "clf.fit(X_train, s)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Iris dataset test accuracy:\", round(accuracy_score(pred, y_test), 2))\n",
    "\n",
    "print(\"\\nNow we show the improvement using confident learning to characterize the noise\")\n",
    "print(\"and learn on the data that is (with high confidence) labeled correctly.\")\n",
    "print()\n",
    "print('WITH confident learning (noise matrix given),', end=\" \")\n",
    "rp.fit(X_train, s, noise_matrix = noise_matrix)\n",
    "pred = rp.predict(X_test)\n",
    "print(\"Iris dataset test accuracy:\", round(accuracy_score(pred, y_test),2))\n",
    "\n",
    "print('WITH confident learning (noise matrix and inverse noise matrix given),', end=\" \")\n",
    "rp.fit(X_train, s, noise_matrix = noise_matrix, inverse_noise_matrix=compute_inv_noise_matrix(py, noise_matrix))\n",
    "pred = rp.predict(X_test)\n",
    "print(\"Iris dataset test accuracy:\", round(accuracy_score(pred, y_test),2))\n",
    "\n",
    "print('WITH confident learning (using latent noise matrix estimation),', end=\" \")\n",
    "rp.fit(X_train, s, prune_count_method='inverse_nm_dot_s')\n",
    "pred = rp.predict(X_test)\n",
    "print(\"Iris dataset test accuracy:\", round(accuracy_score(pred, y_test),2))\n",
    "\n",
    "print('WITH confident learning (using calibrated confident joint),', end=\" \")\n",
    "rp.fit(X_train, s, prune_count_method='calibrate_confident_joint')\n",
    "pred = rp.predict(X_test)\n",
    "print(\"Iris dataset test accuracy:\", round(accuracy_score(pred, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The **rankpruning** algorithm's fit function has a few hyper-parameters. Although the default settings tend to work well, here we show the performance of confident learning across varying parameter settings. To learn more about the hyper-parameter settings, inspect ```confidentlearning/pruning.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param settings: {'prune_count_method': 'calibrate_confident_joint', 'prune_method': 'prune_by_noise_rate', 'converge_estimates': True}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.97\n",
      "\n",
      "Param settings: {'prune_count_method': 'calibrate_confident_joint', 'prune_method': 'prune_by_noise_rate', 'converge_estimates': False}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.97\n",
      "\n",
      "Param settings: {'prune_count_method': 'calibrate_confident_joint', 'prune_method': 'prune_by_class', 'converge_estimates': True}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.87\n",
      "\n",
      "Param settings: {'prune_count_method': 'calibrate_confident_joint', 'prune_method': 'prune_by_class', 'converge_estimates': False}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.87\n",
      "\n",
      "Param settings: {'prune_count_method': 'calibrate_confident_joint', 'prune_method': 'both', 'converge_estimates': True}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.87\n",
      "\n",
      "Param settings: {'prune_count_method': 'calibrate_confident_joint', 'prune_method': 'both', 'converge_estimates': False}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.87\n",
      "\n",
      "Param settings: {'prune_count_method': 'inverse_nm_dot_s', 'prune_method': 'prune_by_noise_rate', 'converge_estimates': True}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.97\n",
      "\n",
      "Param settings: {'prune_count_method': 'inverse_nm_dot_s', 'prune_method': 'prune_by_noise_rate', 'converge_estimates': False}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.93\n",
      "\n",
      "Param settings: {'prune_count_method': 'inverse_nm_dot_s', 'prune_method': 'prune_by_class', 'converge_estimates': True}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.97\n",
      "\n",
      "Param settings: {'prune_count_method': 'inverse_nm_dot_s', 'prune_method': 'prune_by_class', 'converge_estimates': False}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.9\n",
      "\n",
      "Param settings: {'prune_count_method': 'inverse_nm_dot_s', 'prune_method': 'both', 'converge_estimates': True}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.97\n",
      "\n",
      "Param settings: {'prune_count_method': 'inverse_nm_dot_s', 'prune_method': 'both', 'converge_estimates': False}\n",
      "Iris dataset test accuracy (using confident learning):\t 0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "params = {\n",
    "    \"prune_count_method\": [\"calibrate_confident_joint\", \"inverse_nm_dot_s\"],\n",
    "    \"prune_method\": [\"prune_by_noise_rate\", \"prune_by_class\", \"both\"],\n",
    "    \"converge_estimates\": [True, False],\n",
    "}\n",
    "\n",
    "keys, values = zip(*params.items())\n",
    "for v in product(*values):\n",
    "    job = dict(zip(keys, v))\n",
    "    print(\"Param settings:\", job)\n",
    "    rp.fit(\n",
    "        X_train, \n",
    "        s, \n",
    "        prune_method = job['prune_method'],\n",
    "        prune_count_method = job['prune_count_method'],\n",
    "        converge_latent_estimates = job['converge_estimates'],\n",
    "    )\n",
    "    pred = rp.predict(X_test)\n",
    "    print(\"Iris dataset test accuracy (using confident learning):\\t\", round(accuracy_score(pred, y_test),2))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
